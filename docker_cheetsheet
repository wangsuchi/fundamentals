1. the main purpose of docker is to package and containerize apps and to ship them and run them anywhere anytime you want

2. difference between docker vs virtual machine?
  (1)docker shares hardware instructure and os. The containers that run on docker only contains software and its libraries and dependencies
  (2)vm runs on hypervisor, which runs on hardware infrastructure. every vm has its own os and other necessary libraries and dependencies.⇒more isolation
  (3)The vm overhead causes higher utilization of resources,including disk consumption, which is usually gigabytes in size. Wherereas docker container is 
     lightly, which is usually megabytes in size⇒results in faster boot-up
  This is not an either A or B situation. You will often see containers provisioned on virtual machine  
  
3.Containers are meant to run a specific task or process such as to host an instance of a web server or db or application server.
Once the task is complete, the container exits. So a container only lives as long as the process inside it.

4. Container dependent on particular image.

5.docker command
  (1)docker run [image_name]                           if the image is not present on the host it will go out to docker hub and pull it down
  (2)docker run -d [image_name]                        run in the background(in detached mode)
  (3)docker run [image_name:{version_number}]          docker run redis:4.0←tag appended (if not specified, will be the latest version)
  (4)docker run -it [image_name]                       -it instructs Docker to allocate a pseudo-TTY connected to the container’s stdin; creating an interactive bash shell in the container. 
  (5)docker run --name [container_name] [image_name]   you can customize the container name by option --name
  (6)docker run -e [environment_variable] [image_name] when run an image, set an environment variable as well
  
  deprecated --link option: link 2 containers together(docker version)
  (7)docker run -d --name=vote -p 5000:80              
  --link redis:redis voting-app                        to link container redis to the host that the voting app is looking for, which is also redis
  (this,in fact, creates an entry into /etc/hosts on the voting app container, adding a domain name with the internal IP of the redis container)
  
  (8)docker pull [image_name]                          pull image only without running it
  (9)docker ps                                         list all running containers and some basic information(containerID,image,status,names←containerNameRandomlyMadeUpByPC)
  (10)docker ps -a                                     list all running as well as previously stopped or exited containers
  (11)docker stop [containerID/name]
  (12)docker rm [containerID/name]                     delete container for good
  (13)docker images                                    list all images
  (14)docker rmi [image_name]                          Must ensure that no containers are running off of that image before attempting to remove image.Must stop and
                                                       delete all dependent containers before deleting that image.
  (15)docker rm $(docker ps -aq)                       remove all containers at once  
  (16)docker exec [containerID/name] [linux_command]   execute command inside container, docker exec cla19d3a7ca7 cat /etc/hosts
  (17)docker inspect [containerID]                     get information, like the internal ip address of container,the environment variable
  (18)docker build [dockerfile_path] -t [image_name]   build your own image by running dockerfile, option -t is to customize the image name
  (19)docker push [image_name]                         push your image to docker hub.the image name here needs to be changed to [hubdocker_userpath/image_name] 
  (20)docker-compose up                                run compose file
  
6.Run - PORT mapping
docker run -p 80:8080 kodekloud/webapp (map docker host port 80 with container port 8080)
One docker host port can map to only one single container port. 
container has its own default internal ip address, you can access with this ip address inside the docker server.Not working in iMac

Docker: Unable to access container's internal IP from host
https://stackoverflow.com/questions/71155466/docker-unable-to-access-containers-internal-ip-from-host

7.Run- Volume mapping
docker run -v /opt/datadir:/var/lib/mysql mysql(docker_host_path:container_path )
when docker container runs, it will implicitly mount the external directory to a folder inside the docker container.In this way, your data is still there even if the container is deleted.

8. Create my own image
Docker can build images automatically by reading the instructions from a Dockerfile. 
A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. 

Dockerfile example:
INSTRUCTION ARGUMENT
↓　　　　　↓
FROM Ubuntu　　                                        ←start from a base OS or another image,every image must be based of another image.All dockerfile must start from "FROM" instruction
RUN apt-get update && apt-get -y install python       ←install all dependencies
RUN pip install flask flask-mysql                     ←install all dependencies
COPY . /opt/source-code                               ←copy source code
CMD ["command", "param1"]
(①CMD ["sleep","5"])                                 ←hard code to make the system sleep 5 secs every time at startup
(②CMD ["5"]                                          ← default sleep 5 sec
②ENTRYPOINT ["sleep"])                               ←specify entrypoint(allows us to specify a command that will be run when the image is running as a container)
→docker run [image_name] 10 (override CMD layer, entrypoint executes→sleep 10 sec)

layer 1. base ubuntu layer
layer 2. changes in apt packages
layer 3. changes in pip packages
layer 4. sourcecode copy
layer 5. entrypoint

in case step 3 was failed, it will reuse the previous layers from cache and continue to build the remaining layers.
If you were to add additional steps in dockerfile,docker will rebuild the changed layers only.

9. Docker compose
we need to first make sure that all images exist in local host, then we can docker-compose up
use yaml file,docker-compose.yml, to bring up the entire application stack. But it can only work when all containers are in one single docker host.

docker compose- version 1
it attaches all containers it runs to the default bridge network.and then use link to enable communication between the containers 
docker compose- version 2
it automatically creates a dedicated bridge network for this application and then attaches all containers to that new network.all containers are then
able to communicate with each other using its name. no need to use link anymore
docker compose- version 3
has everything of version 2, with support for docker swarm

10. Docker registry
(1)private registry:
https://docs.docker.com/registry/

11.Docker engine
simply refrred to a host with Docker installed on it.

When you install docker on a linux host, you're actually installing 3 different component: Docker CLI, REST API, Docker Deamon.
Docker Deamon: is a background process that manages docker objects such as the images, containers, volummes and networks.
API server: is the API interface that programs can use to talk to the demon and provide instructions.

The Docker CLI does not necessarily be on the same host.It could be on another system like a laptop and can still work with a remote Docker engine.
⇒(command) docker -H=remote-docker-engine-address:2375(port)

























